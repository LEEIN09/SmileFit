<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>íƒ€ì›Œ ë””íœìŠ¤ ì¬í™œ ê²Œì„ | SMILE FIT</title>
    <link rel="shortcut icon" href="{{ url_for('static', filename='unity_game_files/TemplateData/favicon.ico') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='unity_game_files/TemplateData/style.css') }}">
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@500&family=SUIT:wght@400;600&display=swap" rel="stylesheet">
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <style>
        /* ... (ê¸°ì¡´ CSS - ë³€ê²½ ì—†ìŒ) ... */
        body { margin: 0; overflow: hidden; font-family: 'SUIT', sans-serif; text-align: center; background: radial-gradient(ellipse at center, #0f2027, #203a43, #2c5364); color: #00ffe1;}
        #unity-container{
            width: 960px;
            height: 600px;
            margin: auto;
        }
        #facial-recognition-modal {
            display: none;
            position: fixed;
            left: 0; top: 0; width: 100%; height: 100%;
            background-color: rgba(0,0,0,0.85);
            z-index: 1000;
            color: #00ffe1;
            align-items: center;
            justify-content: center;
            flex-direction: column;
            padding: 20px;
            box-sizing: border-box;
        }
        #facial-recognition-modal .modal-container {
            display: flex;
            justify-content: center;
            align-items: flex-start; /* ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ ì •ë ¬ */
            gap: 20px;
            margin-top: 20px;
            flex-wrap: wrap;
        }
        #facial-recognition-modal img,
        #facial-recognition-modal video,
        #facial-recognition-modal canvas { /* canvasë„ ê³µí†µ ìŠ¤íƒ€ì¼ ì ìš© */
            width: 300px;
            height: 225px;
            border: 2px solid #00ffe1;
            box-shadow: 0 0 10px #00ffe1;
            background-color: transparent !important;
        }
        #facial-recognition-modal video { /* ê³µí†µ ë¹„ë””ì˜¤ ìŠ¤íƒ€ì¼ */
            transform: scaleX(-1); /* ì¢Œìš°ë°˜ì „ */
        }
        #facial-recognition-modal .guideCanvas-common { /* ê³µí†µ ê°€ì´ë“œ ìº”ë²„ìŠ¤ */
            position: absolute;
            top:0;
            left:0;
            pointer-events: none;
        }
        #facial-recognition-modal .emotion-display-text,
        #facial-recognition-modal .follow-display-text { /* ê³µí†µ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
            font-size: 18px;
            margin-top: 10px;
            text-shadow: 0 0 5px #00ffe1;
        }
        #facial-recognition-modal button {
            margin-top: 15px;
            padding: 10px 20px;
            font-size: 16px;
            border: 2px solid #00ffe1;
            background: transparent;
            color: #00ffe1;
            border-radius: 10px;
            cursor: pointer;
            box-shadow: 0 0 10px #00ffe1;
            transition: all 0.3s ease;
            margin-left: 5px; /* ë²„íŠ¼ ê°„ ê°„ê²© */
            margin-right: 5px;
        }
        #facial-recognition-modal button:hover {
            background-color: #00ffe133;
            box-shadow: 0 0 15px #00ffe1;
        }
        #facial-recognition-modal button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        #facial-recognition-modal h3 {
            font-family: 'Orbitron', sans-serif;
            font-size: 20px;
            margin-bottom: 5px;
        }
        #facial-recognition-modal p {
            margin-top: 0;
            font-size: 16px;
            color: #fff;
        }
        /* Follow ëª¨ë“œ UIë¥¼ ìœ„í•œ ì¶”ê°€ ìŠ¤íƒ€ì¼ */
        #follow-mode-ui .modal-container div { /* ë¹„ë””ì˜¤ì™€ ìº”ë²„ìŠ¤ë¥¼ ë‹´ëŠ” div */
            position: relative;
        }
        /* Total score display style */
        .session-total-score-display {
            font-weight: bold;
            font-size: 20px !important; /* ensure size override */
            margin-top: 15px !important; /* ensure margin override */
            color: #00ffe1;
            text-shadow: 0 0 8px #00ddcc;
        }
    </style>
</head>
<body>
    <div id="unity-container" class="unity-desktop">
        <canvas id="unity-canvas" width=960 height=600 tabindex="-1"></canvas>
        <div id="unity-loading-bar">
            <div id="unity-logo"></div>
            <div id="unity-progress-bar-empty">
                <div id="unity-progress-bar-full"></div>
            </div>
        </div>
        <div id="unity-warning"> </div>
        <div id="unity-footer">
            <div id="unity-logo-title-footer"></div>
            <div id="unity-fullscreen-button"></div>
            <div id="unity-build-title">towerdefense</div>
        </div>
    </div>

    <div id="facial-recognition-modal">
        <div id="emotion-mode-ui" style="display: none; text-align: center;">
            <h3>ê°ì • í‘œí˜„í•˜ê¸°</h3>
            <p>ì œì‹œëœ ê°ì •ì„ í‘œì •ìœ¼ë¡œ í‘œí˜„í•´ë³´ì„¸ìš”!</p>
            <div class="modal-container">
                <div>
                    <img id="emotion-referenceImg" src="" alt="ê¸°ì¤€ ê°ì • ì´ë¯¸ì§€">
                    <div id="emotion-refEmotionDisplay" class="emotion-display-text">ê¸°ì¤€ ê°ì •: -</div>
                </div>
                <div style="position: relative;">
                    <video id="emotion-video" autoplay muted playsinline></video>
                    <canvas id="emotion-guideCanvas" class="guideCanvas-common" width="300" height="225"></canvas>
                    <div id="emotion-userEmotionDisplay" class="emotion-display-text">ë‹¹ì‹  ê°ì •: -</div>
                </div>
            </div>
            <button id="emotion-captureBtn">ğŸ“¸ í‘œì • ì œì¶œí•˜ê³  ì ìˆ˜ ë°›ê¸°</button>
            <div id="emotion-scoreDisplay" class="emotion-display-text">ì´ë²ˆ ì ìˆ˜: -</div>
            <div id="session-total-score-display-emotion" class="session-total-score-display emotion-display-text">ì´ ì ìˆ˜: 0</div>
        </div>

        <div id="follow-mode-ui" style="display: none; text-align: center;">
            <h3>í‘œì • ë”°ë¼í•˜ê¸°</h3>
            <p>ì œì‹œëœ ë‘ ê°€ì§€ í‘œì • ë³€í™”ë¥¼ ìˆœì„œëŒ€ë¡œ ë”°ë¼í•´ë³´ì„¸ìš”!</p>
            <div class="modal-container">
                <img id="follow-imageA" src="" alt="í‘œì •1">
                <div style="position: relative;">
                    <video id="follow-video" autoplay muted playsinline></video>
                    <canvas id="follow-guideCanvas" class="guideCanvas-common" width="300" height="225"></canvas>
                </div>
                <img id="follow-imageB" src="" alt="í‘œì •2">
            </div>
            <canvas id="follow-output_canvas" width="300" height="225" style="display:none;"></canvas>
            <div>
                <button id="follow-captureA_Btn">1ï¸âƒ£ ì²« ë²ˆì§¸ í‘œì • ë”°ë¼í•˜ê¸°</button>
                <button id="follow-captureB_Btn" disabled>2ï¸âƒ£ ë‘ ë²ˆì§¸ í‘œì • ë”°ë¼í•˜ê¸°</button>
            </div>
            <div id="follow-scoreDisplay" class="follow-display-text">ì´ë²ˆ ì ìˆ˜: -</div>
            <div id="session-total-score-display-follow" class="session-total-score-display follow-display-text">ì´ ì ìˆ˜: 0</div>
        </div>

        <button onclick="closeFacialModal(null, 'manual_close_button')" style="position:absolute; top:20px; right:20px; background-color: #555;">X ë‹«ê¸°</button>
    </div>

<script>
        // --- Unity Loader Script (ê¸°ì¡´ê³¼ ë™ì¼) ---
        var canvas_unity_element = document.querySelector("#unity-canvas");
        function unityShowBanner(msg, type) {
            var warningBanner = document.querySelector("#unity-warning");
            function updateBannerVisibility() {
                warningBanner.style.display = warningBanner.children.length ? 'block' : 'none';
            }
            var div = document.createElement('div');
            div.innerHTML = msg;
            warningBanner.appendChild(div);
            if (type == 'error') div.style = 'background: red; padding: 10px;';
            else {
                if (type == 'warning') div.style = 'background: yellow; padding: 10px;';
                setTimeout(function() {
                    warningBanner.removeChild(div);
                    updateBannerVisibility();
                }, 5000);
            }
            updateBannerVisibility();
        }

        var loaderUrl = "{{ url_for('static', filename='unity_game_files/Build/towerdefense.loader.js') }}";
        var config = {
            arguments: [],
            dataUrl: "{{ url_for('static', filename='unity_game_files/Build/towerdefense.data') }}",
            frameworkUrl: "{{ url_for('static', filename='unity_game_files/Build/towerdefense.framework.js') }}",
            codeUrl: "{{ url_for('static', filename='unity_game_files/Build/towerdefense.wasm') }}",
            productName: "towerdefense",
            showBanner: unityShowBanner,
            devicePixelRatio: 1,
        };

        if (/iPhone|iPad|iPod|Android/i.test(navigator.userAgent)) {
            var meta = document.createElement('meta');
            meta.name = 'viewport';
            meta.content = 'width=device-width, height=device-height, initial-scale=1.0, user-scalable=no, shrink-to-fit=yes';
            document.getElementsByTagName('head')[0].appendChild(meta);
            document.querySelector("#unity-container").className = "unity-mobile";
            if (canvas_unity_element) canvas_unity_element.className = "unity-mobile";
        }
        document.querySelector("#unity-loading-bar").style.display = "block";

        var script_unity = document.createElement("script");
        script_unity.src = loaderUrl;
        script_unity.onload = () => {
            createUnityInstance(canvas_unity_element, config, (progress) => {
                document.querySelector("#unity-progress-bar-full").style.width = 100 * progress + "%";
            }).then((unityInstance) => {
                window.unityGameInstance = unityInstance;
                console.log("Unity Instance Loaded and assigned to window.unityGameInstance!");
                document.querySelector("#unity-loading-bar").style.display = "none";
                if (document.querySelector("#unity-fullscreen-button")) {
                    document.querySelector("#unity-fullscreen-button").onclick = () => {
                        unityInstance.SetFullscreen(1);
                    };
                }
            }).catch((message) => {
                alert(message);
            });
        };
        document.body.appendChild(script_unity);

        // ==================================================
        // ğŸ‘‡ ì–¼êµ´ í‰ê°€ ê´€ë ¨ JavaScript ë¡œì§ ğŸ‘‡
        // ==================================================

        let currentActiveFacialMode = null;
        let currentSessionTotalScore = 0; // âœ… ëˆ„ì  ì ìˆ˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì¶”ê°€
        let sessionTotalScoreDisplayElement = null; // âœ… ì´ì  í‘œì‹œìš© DOM ìš”ì†Œ ì €ì¥ ë³€ìˆ˜


        // --- Emotion Expression Mode Variables & Functions ---
        let faceApiModelLoaded_Emotion = false;
        const emotionModeUI = document.getElementById('emotion-mode-ui');
        const emotionReferenceImg = document.getElementById('emotion-referenceImg');
        const emotionVideo = document.getElementById('emotion-video');
        const emotionScoreDisplay = document.getElementById('emotion-scoreDisplay'); // For individual attempt score
        const emotionRefEmotionDisplay = document.getElementById('emotion-refEmotionDisplay');
        const emotionUserEmotionDisplay = document.getElementById('emotion-userEmotionDisplay');
        const emotionCaptureBtn = document.getElementById('emotion-captureBtn');
        const emotionGuideCanvas = document.getElementById('emotion-guideCanvas');
        const emotionImageCount = 50;
        const emotionImageIndices = Array.from({ length: emotionImageCount }, (_, i) => i + 1);
        let currentEmotionReferenceImageNumber = 0;

        const baseImagePath_emotion = "/static/images/e_game/";

        async function loadEmotionModels() {
            if (faceApiModelLoaded_Emotion) { console.log("Emotion models already loaded."); return true; }
            if (typeof faceapi === 'undefined') {
                console.error("face-api.js is not loaded yet!");
                alert("ì–¼êµ´ ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(face-api) ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
                return false;
            }
            let modelPath = "/models";
            try {
                console.log("Loading face-api.js models for emotion mode...");
                await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);
                await faceapi.nets.faceExpressionNet.loadFromUri(modelPath);
                await faceapi.nets.faceLandmark68Net.loadFromUri(modelPath);
                faceApiModelLoaded_Emotion = true;
                console.log("Emotion mode (face-api.js) models loaded successfully from:", modelPath);
                return true;
            } catch (error) {
                console.error(`Error loading face-api.js models. Attempted base path: '${modelPath}'. Details:`, error);
                alert("ì–¼êµ´ ì¸ì‹ ëª¨ë¸(ê°ì •) ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ ê²½ë¡œ ë° ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\n(ê°œë°œì ë„êµ¬ ì½˜ì†”ì—ì„œ ìƒì„¸ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.)");
                return false;
            }
        }
        async function startVideoForEmotionMode() {
            if (emotionVideo.srcObject && emotionVideo.srcObject.active) {
                console.log("Webcam for emotion mode is already active.");
                if (emotionVideo.paused) {
                    try {
                        console.log("Attempting to play previously paused video for emotion mode...");
                        await emotionVideo.play();
                        console.log("Restarted paused video for emotion mode.");
                    } catch (e) {
                        console.error("Error restarting paused video for emotion mode:", e);
                        return false;
                    }
                }
                if (emotionVideo.readyState >= HTMLMediaElement.HAVE_METADATA && emotionVideo.videoWidth > 0) {
                     if (emotionGuideCanvas && emotionGuideCanvas.style.display !== 'none') {
                         try {
                             emotionGuideCanvas.width = emotionVideo.clientWidth || 300;
                             emotionGuideCanvas.height = emotionVideo.clientHeight || 225;
                             drawGuideEllipseForEmotion();
                             console.log("Drew guide ellipse for already active video (checked state).");
                         } catch (e) {
                             console.error("Error drawing guide for active video (checked state):", e);
                         }
                    }
                }
                return true;
            }
            try {
                console.log("Requesting webcam for emotion mode (getUserMedia)...");
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                console.log("getUserMedia successful for emotion mode. Stream received:", stream);
                emotionVideo.srcObject = stream;

                console.log("Attempting emotionVideo.play() for emotion mode...");
                await emotionVideo.play();
                console.log("emotionVideo.play() promise resolved for emotion mode.");
                
                const videoReadyPromise = new Promise((resolve) => {
                    let attempts = 0;
                    const maxAttempts = 20; 
                    let intervalId = null;
                    let eventOrPollFired = false; 

                    const commonSuccessActions = () => {
                        if (emotionGuideCanvas && emotionGuideCanvas.style.display !== 'none') {
                            try {
                                emotionGuideCanvas.width = emotionVideo.clientWidth || 300;
                                emotionGuideCanvas.height = emotionVideo.clientHeight || 225;
                                drawGuideEllipseForEmotion();
                            } catch (e) { console.error("Error drawing guide in commonSuccessActions:", e); }
                        }
                        resolve(true);
                    };
                    const cleanup = () => {
                        if (intervalId) clearInterval(intervalId);
                        emotionVideo.onloadedmetadata = null; emotionVideo.onerror = null; emotionVideo.oncanplay = null; 
                    };
                    const checkVideoStateByPolling = () => {
                        if (eventOrPollFired) return; 
                        attempts++;
                        if (emotionVideo.readyState >= HTMLMediaElement.HAVE_METADATA && emotionVideo.videoWidth > 0) {
                            eventOrPollFired = true; cleanup(); commonSuccessActions();
                        } else if (attempts >= maxAttempts) {
                            eventOrPollFired = true; cleanup(); resolve(false);
                        }
                    };
                    emotionVideo.onloadedmetadata = () => { if (eventOrPollFired) return; eventOrPollFired = true; cleanup(); commonSuccessActions(); };
                    emotionVideo.onerror = (e) => { if (eventOrPollFired) return; eventOrPollFired = true; cleanup(); resolve(false); };
                    intervalId = setInterval(checkVideoStateByPolling, 500);
                });
                return await videoReadyPromise;
            } catch (err) {
                console.error("Error in startVideoForEmotionMode (e.g., getUserMedia failed or play() rejected):", err);
                alert("ì›¹ìº (ê°ì •)ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ê¶Œí•œ ë° ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”. (ì—ëŸ¬: " + err.name + ")");
                return false;
            }
        }

        function drawGuideEllipseForEmotion() {
            if (!emotionGuideCanvas || !emotionVideo.srcObject || emotionVideo.clientWidth === 0 || emotionGuideCanvas.style.display === 'none') return;
            const ctx = emotionGuideCanvas.getContext("2d");
            ctx.clearRect(0, 0, emotionGuideCanvas.width, emotionGuideCanvas.height);
            ctx.strokeStyle = "rgba(0, 255, 0, 0.6)";
            ctx.lineWidth = 3;
            ctx.beginPath();
            ctx.ellipse(emotionGuideCanvas.width / 2, emotionGuideCanvas.height / 2,
                        emotionGuideCanvas.width * 0.25, emotionGuideCanvas.height * 0.38, 0, 0, 2 * Math.PI);
            ctx.stroke();
        }

        async function setupSingleEmotionExercise() {
            console.log("Setting up single emotion exercise...");
            if(emotionCaptureBtn) emotionCaptureBtn.disabled = true; // Disable button until new exercise is ready

            currentEmotionReferenceImageNumber = emotionImageIndices[Math.floor(Math.random() * emotionImageIndices.length)];
            const imageUrl = `${baseImagePath_emotion}e${currentEmotionReferenceImageNumber}.png`;
            emotionReferenceImg.src = imageUrl;

            emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: - (ì´ë¯¸ì§€ ë¶„ì„ì¤‘...)`;
            emotionUserEmotionDisplay.innerHTML = `ë‹¹ì‹  ê°ì •: -`;
            if (emotionScoreDisplay) emotionScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: -`;


            try {
                await waitForImageLoadForModal(emotionReferenceImg);
                const refResult = await tryRecognizeReferenceEmotionForModal(true);
                if (refResult && refResult.expressions) {
                    const refEmotion = getTopEmotion(refResult.expressions);
                    emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: <b>${refEmotion}</b>`;
                } else {
                    emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: (ë¶„ì„ ì‹¤íŒ¨)`;
                }
            } catch (error) {
                console.error("Failed to load or process reference image in setupSingleEmotionExercise:", error);
                emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: (ì´ë¯¸ì§€ ì˜¤ë¥˜)`;
            }
            if(emotionCaptureBtn) emotionCaptureBtn.disabled = false; // Re-enable button
        }

        function cosineSimilarity(a, b) {
            if (!a || !b || a.length !== b.length || a.length === 0) return 0;
            const dot = a.reduce((sum, val, i) => sum + val * b[i], 0);
            const magA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
            const magB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
            if (magA === 0 || magB === 0) return 0;
            return dot / (magA * magB);
        }

        function waitForImageLoadForModal(imgElement) {
             return new Promise((resolve, reject) => {
                if (imgElement.complete && imgElement.naturalHeight !== 0 && imgElement.src && imgElement.src !== window.location.href ) { resolve(); }
                else {
                    imgElement.onload = () => resolve();
                    imgElement.onerror = () => {
                        reject(new Error("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: " + imgElement.src));
                    };
                }
            });
        }

        async function tryRecognizeReferenceEmotionForModal(isSetup = false, maxAttempts = 3) {
            if (!faceApiModelLoaded_Emotion) { return null; }
            for (let attempt = 0; attempt < maxAttempts; attempt++) {
                try {
                    await waitForImageLoadForModal(emotionReferenceImg);
                    const refResult = await faceapi
                        .detectSingleFace(emotionReferenceImg, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceExpressions();
                    if (refResult && refResult.expressions) return refResult;
                } catch (error) { console.error(`Error in tryRecognizeReferenceEmotionForModal (attempt ${attempt + 1}):`, error); }

                if (attempt < maxAttempts - 1) {
                    const originalImageNum = currentEmotionReferenceImageNumber;
                    let newImageNum;
                    do { newImageNum = emotionImageIndices[Math.floor(Math.random() * emotionImageIndices.length)]; }
                    while (newImageNum === originalImageNum && emotionImageIndices.length > 1);
                    currentEmotionReferenceImageNumber = newImageNum;
                    emotionReferenceImg.src = `${baseImagePath_emotion}e${currentEmotionReferenceImageNumber}.png`;
                    emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: - (ë‹¤ë¥¸ ì´ë¯¸ì§€ ë¶„ì„ì¤‘...)`;
                    await new Promise(resolve => setTimeout(resolve, 200)); // Brief pause for image to potentially load
                }
            }
            return null;
        }

        const getTopEmotion = exp => Object.entries(exp).sort((a, b) => b[1] - a[1])[0][0];

        async function processEmotionExpression() {
            console.log("processEmotionExpression: Function started.");
            if (!faceApiModelLoaded_Emotion) { return; }
            if (!emotionVideo.srcObject || emotionVideo.paused || emotionVideo.ended || emotionVideo.readyState < 3) {
                if(emotionCaptureBtn) emotionCaptureBtn.disabled = false; // Re-enable if video error
                return;
            }

            if(emotionCaptureBtn) emotionCaptureBtn.disabled = true;
            if (emotionScoreDisplay) emotionScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: ë¶„ì„ ì¤‘...`;

            let userDetections;
            try {
                userDetections = await faceapi.detectSingleFace(emotionVideo, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
            } catch (error) {
                console.error("Error during user face detection:", error);
                if (emotionScoreDisplay) emotionScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: ì‚¬ìš©ì ë¶„ì„ ì‹¤íŒ¨`;
                currentSessionTotalScore += 0;
                if (sessionTotalScoreDisplayElement) sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore;
                await setupSingleEmotionExercise(); // Prepare for next attempt
                // emotionCaptureBtn will be re-enabled by setupSingleEmotionExercise
                return;
            }

            if (!userDetections || !userDetections.expressions) {
                if (emotionScoreDisplay) emotionScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: ì–¼êµ´/í‘œì • ë¯¸ê°ì§€`;
                currentSessionTotalScore += 0;
                if (sessionTotalScoreDisplayElement) sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore;
                await setupSingleEmotionExercise();
                return;
            }
            const userEmotion = getTopEmotion(userDetections.expressions);
            emotionUserEmotionDisplay.innerHTML = `ë‹¹ì‹  ê°ì •: <b>${userEmotion}</b>`;

            let refResult = await tryRecognizeReferenceEmotionForModal(false, 1);

            if (!refResult || !refResult.expressions) {
                if (emotionScoreDisplay) emotionScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: ê¸°ì¤€ ë¶„ì„ ì‹¤íŒ¨`;
                currentSessionTotalScore += 0;
                if (sessionTotalScoreDisplayElement) sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore;
                await setupSingleEmotionExercise();
                return;
            }

            const refVec = Object.values(refResult.expressions);
            const userVec = Object.values(userDetections.expressions);
            const sim = cosineSimilarity(refVec, userVec);
            const calculatedScore = Math.max(3, Math.min(10, Math.round(sim * 10)));
            console.log("processEmotionExpression: Similarity:", sim, "Calculated score:", calculatedScore);

            if (emotionScoreDisplay) emotionScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: <b>${calculatedScore} / 10</b>`;
            currentSessionTotalScore += calculatedScore; // âœ… ì ìˆ˜ ëˆ„ì 
            if (sessionTotalScoreDisplayElement) {
                sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore; // âœ… ì´ì  UI ì—…ë°ì´íŠ¸
            }

            // âœ… ë‹¤ìŒ ì‹œë„ë¥¼ ìœ„í•´ ìš´ë™ ì¬ì„¤ì •
            await setupSingleEmotionExercise(); // ìƒˆ ì´ë¯¸ì§€ë¡œ ë‹¤ìŒ ì‹œë„ ì¤€ë¹„ ë° ë²„íŠ¼ ì¬í™œì„±í™”
        }


        // --- Follow Expression Mode Variables & Functions ---
        let faceApiModelLoaded_Follow = false;
        const followModeUI = document.getElementById('follow-mode-ui');
        const followImageA = document.getElementById('follow-imageA');
        const followImageB = document.getElementById('follow-imageB');
        const followVideo = document.getElementById('follow-video');
        const followGuideCanvas = document.getElementById('follow-guideCanvas');
        const followOutputCanvas = document.getElementById('follow-output_canvas');
        const followCaptureABtn = document.getElementById('follow-captureA_Btn');
        const followCaptureBBtn = document.getElementById('follow-captureB_Btn');
        const followScoreDisplay = document.getElementById('follow-scoreDisplay'); // For individual attempt score

        let faceMesh_Follow = null;
        let camera_Follow = null;
        let latestLandmarks_Follow = null;
        let userA_Follow_Landmarks = null;
        let userB_Follow_Landmarks = null;
        let teacherA_Follow_Landmarks = null;
        let teacherB_Follow_Landmarks = null;
        let staticFaceMesh_Follow = null;

        const followImageCount = 50; // Assuming 25 pairs
        let currentFollowImageSet = 0;

        async function loadFollowModels() {
            if (faceApiModelLoaded_Follow) { console.log("Follow models (MediaPipe) already loaded."); return true; }
            if (typeof FaceMesh === 'undefined' || typeof Camera === 'undefined') {
                alert("ì–¼êµ´ ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(MediaPipe) ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
                return false;
            }
            try {
                faceMesh_Follow = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/${file}`});
                faceMesh_Follow.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
                faceMesh_Follow.onResults(onFollowResults);

                staticFaceMesh_Follow = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/${file}`});
                staticFaceMesh_Follow.setOptions({ maxNumFaces: 1, refineLandmarks: true, staticImageMode: true });

                faceApiModelLoaded_Follow = true;
                return true;
            } catch (error) {
                alert("ì–¼êµ´ ì¸ì‹ ëª¨ë¸(í‘œì •ë”°ë¼í•˜ê¸°) ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
                return false;
            }
        }

        function onFollowResults(results) {
            const ctx = followOutputCanvas.getContext('2d');
            ctx.save();
            ctx.clearRect(0, 0, followOutputCanvas.width, followOutputCanvas.height);
            ctx.scale(-1, 1); ctx.translate(-followOutputCanvas.width, 0);
            ctx.drawImage(results.image, 0, 0, followOutputCanvas.width, followOutputCanvas.height);
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                latestLandmarks_Follow = structuredClone(results.multiFaceLandmarks[0]);
            }
            ctx.restore();
        }

        async function startVideoForFollowMode() {
            if (camera_Follow && camera_Follow.video && camera_Follow.video.srcObject && camera_Follow.video.srcObject.active) {
                 if (camera_Follow.video.paused) camera_Follow.video.play().catch(e => console.error("Error restarting paused video:", e));
                 return true;
            }
            if (!faceMesh_Follow) return false;
            try {
                camera_Follow = new Camera(followVideo, {
                    onFrame: async () => {
                        if (followVideo.readyState >= HTMLMediaElement.HAVE_CURRENT_DATA) {
                           await faceMesh_Follow.send({image: followVideo});
                        }
                    },
                    width: 300, height: 225
                });
                await camera_Follow.start();
                followVideo.onloadedmetadata = () => {
                    if (followGuideCanvas && followGuideCanvas.style.display !== 'none') {
                        followGuideCanvas.width = followVideo.clientWidth || 300;
                        followGuideCanvas.height = followVideo.clientHeight || 225;
                        drawGuideEllipseForFollow();
                    }
                };
                if (followVideo.clientWidth > 0 && followGuideCanvas && followGuideCanvas.style.display !== 'none') { // Initial draw if already sized
                    followGuideCanvas.width = followVideo.clientWidth;
                    followGuideCanvas.height = followVideo.clientHeight;
                    drawGuideEllipseForFollow();
                }
                return true;
            } catch (err) {
                alert("ì›¹ìº (í‘œì •ë”°ë¼í•˜ê¸°)ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ê¶Œí•œ ë° ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”. (ì—ëŸ¬: " + err.name + ")");
                return false;
            }
        }

        function drawGuideEllipseForFollow() {
            if (!followGuideCanvas || !followVideo.srcObject || followVideo.clientWidth === 0 || followGuideCanvas.style.display === 'none') return;
            const ctx = followGuideCanvas.getContext("2d");
            ctx.clearRect(0, 0, followGuideCanvas.width, followGuideCanvas.height);
            ctx.strokeStyle = "rgba(0, 255, 0, 0.6)";
            ctx.lineWidth = 3;
            ctx.beginPath();
            ctx.ellipse(followGuideCanvas.width / 2, followGuideCanvas.height / 2,
                        followGuideCanvas.width * 0.25, followGuideCanvas.height * 0.38, 0, 0, 2 * Math.PI);
            ctx.stroke();
        }

        async function getImageLandmarksAsync_Follow(imgElement) {
            if (!staticFaceMesh_Follow) return null;
            return new Promise(async (resolve) => {
                try {
                    await waitForImageLoadForModal(imgElement);
                    const tempOnResults = (results) => {
                        staticFaceMesh_Follow.onResults(null); // Remove listener once triggered
                        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) resolve(structuredClone(results.multiFaceLandmarks[0]));
                        else resolve(null);
                    };
                    staticFaceMesh_Follow.onResults(tempOnResults); // Set one-time listener
                    await staticFaceMesh_Follow.send({ image: imgElement });
                } catch (error) { resolve(null); }
            });
        }

        async function preloadTeacherLandmarks_Follow() {
            followCaptureABtn.disabled = true;
            followCaptureBBtn.disabled = true;
            if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: ê¸°ì¤€ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...";

            try {
                teacherA_Follow_Landmarks = await getImageLandmarksAsync_Follow(followImageA);
                teacherB_Follow_Landmarks = await getImageLandmarksAsync_Follow(followImageB);

                if (!teacherA_Follow_Landmarks || !teacherB_Follow_Landmarks) {
                    throw new Error("ê¸°ì¤€ ì´ë¯¸ì§€ ì¤‘ í•˜ë‚˜ ë˜ëŠ” ëª¨ë‘ì—ì„œ ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ ì‹¤íŒ¨");
                }
                console.log("âœ… Follow Mode: ê¸°ì¤€ ì´ë¯¸ì§€ ëœë“œë§ˆí¬ ì¶”ì¶œ ì™„ë£Œ");
                followCaptureABtn.disabled = false;
                if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: -";
            } catch (err) {
                alert("âš ï¸ ê¸°ì¤€ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: " + err.message + "\në‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ ì‹œë„í•©ë‹ˆë‹¤.");
                await setupSingleFollowExercise_Follow(true); // Retry with new images
            }
        }

        async function setupSingleFollowExercise_Follow(isRetry = false) {
            console.log("Setting up single follow expression exercise...");
            followCaptureABtn.disabled = true; // Disable buttons until ready
            followCaptureBBtn.disabled = true;

            if (!isRetry) {
                currentFollowImageSet = Math.floor(Math.random() * (followImageCount / 2));
            } else {
                currentFollowImageSet = (currentFollowImageSet + 1) % (followImageCount / 2);
            }
            const imgNum1 = currentFollowImageSet * 2 + 1;
            const imgNum2 = currentFollowImageSet * 2 + 2;

            followImageA.src = `{{ url_for('static', filename='images/f_game/') }}${imgNum1}.png`;
            followImageB.src = `{{ url_for('static', filename='images/f_game/') }}${imgNum2}.png`;

            if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: -";
            userA_Follow_Landmarks = null;
            userB_Follow_Landmarks = null;

            try {
                await Promise.all([waitForImageLoadForModal(followImageA), waitForImageLoadForModal(followImageB)]);
                await preloadTeacherLandmarks_Follow(); // This will enable followCaptureABtn if successful
            } catch (error) {
                if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: ê¸°ì¤€ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜";
                alert("í‘œì • ë”°ë¼í•˜ê¸° ê¸°ì¤€ ì´ë¯¸ì§€ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
                // Potentially call closeFacialModal or allow another setup attempt. For now, it retries via preloadTeacherLandmarks_Follow's catch.
            }
        }

        function normalizeLandmarks_Follow(landmarks) {
            if (!landmarks || landmarks.length === 0) return [];
            const leftEye = landmarks[33]; const rightEye = landmarks[263];
            let centerX, centerY, scale;
            if (!leftEye || !rightEye) { // Fallback if specific eye landmarks are not found (should be rare with MediaPipe)
                centerX = landmarks.reduce((sum, p) => sum + p.x, 0) / landmarks.length;
                centerY = landmarks.reduce((sum, p) => sum + p.y, 0) / landmarks.length;
                const minX = Math.min(...landmarks.map(p=>p.x)); const maxX = Math.max(...landmarks.map(p=>p.x));
                const minY = Math.min(...landmarks.map(p=>p.y)); const maxY = Math.max(...landmarks.map(p=>p.y));
                scale = Math.hypot(maxX - minX, maxY - minY) || 1;
            } else {
                centerX = (leftEye.x + rightEye.x) / 2;
                centerY = (leftEye.y + rightEye.y) / 2;
                scale = Math.hypot(leftEye.x - rightEye.x, leftEye.y - rightEye.y) || 1;
            }
            return landmarks.map(p => ({ x: (p.x - centerX) / scale, y: (p.y - centerY) / scale, z: (p.z || 0) / scale }));
        }

        function computeDelta_Follow(landmarksA, landmarksB) {
            if (!landmarksA || !landmarksB || landmarksA.length !== landmarksB.length) return [];
            return landmarksA.map((pA, i) => {
                const pB = landmarksB[i];
                return { x: pA.x - pB.x, y: pA.y - pB.y, z: (pA.z || 0) - (pB.z || 0) };
            });
        }

        const weightMap_Follow = { eyes: 0.2, mouth: 0.4, eyebrows: 0.2, nose: 0.1, jaw: 0.1 };
        const regions_Follow = { /* ... (regions_Follow unchanged) ... */ };

        function getWeightedDeltaScore_Follow(delta1, delta2) {
            if (!delta1 || !delta2 || delta1.length === 0 || delta1.length !== delta2.length) return 0;
            let sumOfWeightedRegionErrors = 0; let totalWeightUsed = 0;
            for (const [region, indices] of Object.entries(regions_Follow)) {
                if (!indices || indices.length === 0) continue;
                const weight = weightMap_Follow[region] || 0.1;
                let regionErrorSum = 0; let validPointsInRegion = 0;
                for (const i of indices) {
                    if (i < delta1.length && i < delta2.length) {
                        const d1p = delta1[i]; const d2p = delta2[i];
                        const dx = d1p.x - d2p.x; const dy = d1p.y - d2p.y; const dz = (d1p.z || 0) - (d2p.z || 0);
                        regionErrorSum += Math.sqrt(dx*dx + dy*dy + dz*dz);
                        validPointsInRegion++;
                    }
                }
                if (validPointsInRegion > 0) {
                    sumOfWeightedRegionErrors += (regionErrorSum / validPointsInRegion) * weight;
                    totalWeightUsed += weight;
                }
            }
            if (totalWeightUsed === 0) return 0;
            const averageWeightedError = sumOfWeightedRegionErrors / totalWeightUsed;
            const score = Math.max(1, Math.round(10 - averageWeightedError * 50)); // *50 is an arbitrary scaler, adjust as needed
            return Math.min(10, score);
        }

        async function processFollowExpression_CaptureA() {
            if (!latestLandmarks_Follow) { alert("âŒ ì–¼êµ´ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); return; }
            userA_Follow_Landmarks = structuredClone(latestLandmarks_Follow);
            followCaptureABtn.disabled = true;
            followCaptureBBtn.disabled = false;
            if(followScoreDisplay) followScoreDisplay.innerHTML = "ì²« ë²ˆì§¸ í‘œì • ì €ì¥ë¨. ë‘ ë²ˆì§¸ í‘œì •ì„ ì¤€ë¹„í•˜ì„¸ìš”.";
        }

        async function processFollowExpression_CaptureB() {
            if (!latestLandmarks_Follow) { alert("âŒ ì–¼êµ´ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); return; }
            if (!userA_Follow_Landmarks || !teacherA_Follow_Landmarks || !teacherB_Follow_Landmarks) {
                alert("âŒ ë°ì´í„° ë¶€ì¡±. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
                await setupSingleFollowExercise_Follow(); return;
            }
            userB_Follow_Landmarks = structuredClone(latestLandmarks_Follow);
            followCaptureBBtn.disabled = true;
            if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: ê³„ì‚° ì¤‘...";

            const normTeacherA = normalizeLandmarks_Follow(teacherA_Follow_Landmarks);
            const normTeacherB = normalizeLandmarks_Follow(teacherB_Follow_Landmarks);
            const normUserA = normalizeLandmarks_Follow(userA_Follow_Landmarks);
            const normUserB = normalizeLandmarks_Follow(userB_Follow_Landmarks);

            if (normTeacherA.length === 0 || normTeacherB.length === 0 || normUserA.length === 0 || normUserB.length === 0) {
                 alert("ëœë“œë§ˆí¬ ì •ê·œí™” ì‹¤íŒ¨.");
                 if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: ë¶„ì„ ì˜¤ë¥˜";
                 currentSessionTotalScore += 0;
                 if (sessionTotalScoreDisplayElement) sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore;
                 await setupSingleFollowExercise_Follow(); // Reset for next attempt
                 return;
            }
            const teacherDelta = computeDelta_Follow(normTeacherB, normTeacherA);
            const userDelta = computeDelta_Follow(normUserB, normUserA);

            if (teacherDelta.length === 0 || userDelta.length === 0) {
                alert("í‘œì • ë³€í™”ëŸ‰ ê³„ì‚° ì‹¤íŒ¨.");
                if(followScoreDisplay) followScoreDisplay.innerHTML = "ì´ë²ˆ ì ìˆ˜: ë¶„ì„ ì˜¤ë¥˜";
                currentSessionTotalScore += 0;
                if (sessionTotalScoreDisplayElement) sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore;
                await setupSingleFollowExercise_Follow();
                return;
            }

            const calculatedScore = getWeightedDeltaScore_Follow(teacherDelta, userDelta);
            if(followScoreDisplay) followScoreDisplay.innerHTML = `ì´ë²ˆ ì ìˆ˜: <b>${calculatedScore} / 10</b>`;
            currentSessionTotalScore += calculatedScore; // âœ… ì ìˆ˜ ëˆ„ì 
            if (sessionTotalScoreDisplayElement) {
                sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: ' + currentSessionTotalScore; // âœ… ì´ì  UI ì—…ë°ì´íŠ¸
            }

            // âœ… ë‹¤ìŒ A/B ì‹œë„ë¥¼ ìœ„í•´ ì´ˆê¸°í™”
            await setupSingleFollowExercise_Follow(); // ìƒˆ ë¬¸ì œ ì„¤ì • ë° ë²„íŠ¼ ìƒíƒœ ì´ˆê¸°í™”
        }

        async function ShowFacialRecognitionUI_JS(modeFromUnity, attempt = 1) {
            console.log(`ShowFacialRecognitionUI_JS called. Mode: ${modeFromUnity}, Attempt: ${attempt}`);
            const urlParams = new URLSearchParams(window.location.search);
            let actualMode = urlParams.get('mode') || modeFromUnity;
            if (!actualMode) { closeFacialModal(null, "error_undefined_mode"); return; }

            currentActiveFacialMode = actualMode;
            currentSessionTotalScore = 0; // âœ… ì„¸ì…˜ ì‹œì‘ ì‹œ ì´ì  ì´ˆê¸°í™”

            // âœ… ì´ì  í‘œì‹œ UI ìš”ì†Œ ê°€ì ¸ì˜¤ê¸° ë° ì´ˆê¸°í™”
            if (actualMode === 'emotion_expression') {
                sessionTotalScoreDisplayElement = document.getElementById('session-total-score-display-emotion');
            } else if (actualMode === 'follow_expression') {
                sessionTotalScoreDisplayElement = document.getElementById('session-total-score-display-follow');
            }
            if (sessionTotalScoreDisplayElement) {
                sessionTotalScoreDisplayElement.innerText = 'ì´ ì ìˆ˜: 0';
            }
            // Reset individual attempt scores
            if (emotionScoreDisplay) emotionScoreDisplay.innerText = 'ì´ë²ˆ ì ìˆ˜: -';
            if (followScoreDisplay) followScoreDisplay.innerText = 'ì´ë²ˆ ì ìˆ˜: -';


            const modal = document.getElementById('facial-recognition-modal');
            if (!modal) { closeFacialModal(currentActiveFacialMode, "error_modal_element_missing"); return; }

            if (emotionModeUI) emotionModeUI.style.display = 'none';
            if (followModeUI) followModeUI.style.display = 'none';
            if (emotionGuideCanvas) emotionGuideCanvas.style.display = 'none';
            if (followGuideCanvas) followGuideCanvas.style.display = 'none';
            modal.style.display = 'flex';

            if (actualMode === 'emotion_expression') {
                if (typeof faceapi === 'undefined') { /* ... retry logic ... */ if (attempt < 5) { setTimeout(() => ShowFacialRecognitionUI_JS(modeFromUnity, attempt + 1), 500); return; } else { alert("face-api.js ë¡œë”© ì‹¤íŒ¨."); closeFacialModal(currentActiveFacialMode, "error_faceapi_load_failed"); return; } }
                if (typeof faceapi !== 'undefined' && !window.faceApiBackendManuallySet) { /* ... backend setup ... */ try { if (faceapi.tf && faceapi.tf.setBackend) { try { await faceapi.tf.setBackend('wasm'); } catch (eWasm) { try { await faceapi.tf.setBackend('cpu'); } catch (eCpu) { console.error("Failed to set CPU backend for face-api.js:", eCpu.message);}}} window.faceApiBackendManuallySet = true; } catch (e) { console.error("Error during manual face-api.js backend setup:", e); } await new Promise(resolve => setTimeout(resolve, 0));}

                if (!emotionModeUI) { closeFacialModal(currentActiveFacialMode, "error_emotion_ui_missing"); return; }
                emotionModeUI.style.display = 'block'; if (emotionGuideCanvas) emotionGuideCanvas.style.display = 'block';

                if (!faceApiModelLoaded_Emotion) { const modelsLoaded = await loadEmotionModels(); if (!modelsLoaded) { closeFacialModal(currentActiveFacialMode, "error_emotion_models_not_loaded"); return; } await new Promise(resolve => setTimeout(resolve, 0)); }
                const videoStarted = await startVideoForEmotionMode(); if (!videoStarted) { closeFacialModal(currentActiveFacialMode, "error_emotion_video_not_started"); return; } await new Promise(resolve => setTimeout(resolve, 0));

                await setupSingleEmotionExercise(); // This will also enable the button
                emotionCaptureBtn.removeEventListener('click', processEmotionExpression); // Ensure no duplicates
                emotionCaptureBtn.addEventListener('click', processEmotionExpression);

            } else if (actualMode === 'follow_expression') {
                if (typeof FaceMesh === 'undefined' || typeof Camera === 'undefined') { /* ... retry logic ... */ if (attempt < 5) { setTimeout(() => ShowFacialRecognitionUI_JS(modeFromUnity, attempt + 1), 500); return; } else { alert("MediaPipe ë¡œë”© ì‹¤íŒ¨."); closeFacialModal(currentActiveFacialMode, "error_mediapipe_load_failed"); return; } }

                if (!followModeUI) { closeFacialModal(currentActiveFacialMode, "error_follow_ui_missing"); return; }
                followModeUI.style.display = 'block'; if (followGuideCanvas) followGuideCanvas.style.display = 'block';

                if (!faceApiModelLoaded_Follow) { const modelsLoaded = await loadFollowModels(); if (!modelsLoaded) { closeFacialModal(currentActiveFacialMode, "error_follow_models_not_loaded"); return; } await new Promise(resolve => setTimeout(resolve, 0)); }
                const videoStarted = await startVideoForFollowMode(); if (!videoStarted) { closeFacialModal(currentActiveFacialMode, "error_follow_video_not_started"); return; } await new Promise(resolve => setTimeout(resolve, 0));

                await setupSingleFollowExercise_Follow(); // This will also manage button states

                followCaptureABtn.removeEventListener('click', processFollowExpression_CaptureA); // Ensure no duplicates
                followCaptureABtn.addEventListener('click', processFollowExpression_CaptureA);
                followCaptureBBtn.removeEventListener('click', processFollowExpression_CaptureB); // Ensure no duplicates
                followCaptureBBtn.addEventListener('click', processFollowExpression_CaptureB);
            } else {
                alert("ì•Œ ìˆ˜ ì—†ëŠ” ì–¼êµ´ ìš´ë™ ëª¨ë“œì…ë‹ˆë‹¤: " + actualMode);
                closeFacialModal(actualMode, "error_unknown_mode");
            }
        }

        // sendScoreToUnityAndHideModal is no longer used for individual attempts.
        // function sendScoreToUnityAndHideModal(score, modeWhenCalled) { ... }

        function closeFacialModal(modeToClose = null, reason = "manual_close") {
            const modeForClosing = modeToClose || currentActiveFacialMode;
            console.log(`Closing facial modal for mode: ${modeForClosing}, Reason: ${reason}, Accumulated Score: ${currentSessionTotalScore}`);

            // Send final accumulated score to Unity if closed by Unity (e.g. timer)
            // Assuming Unity will pass a specific reason like "session_ended_by_unity" or "closed_by_unity_timer"
            if (reason && (reason.startsWith("session_ended_by_unity") || reason.startsWith("closed_by_unity"))) {
                if (window.unityGameInstance) {
                    console.log("Sending FINAL accumulated score to Unity:", currentSessionTotalScore);
                    window.unityGameInstance.SendMessage('CostManagerObject', 'ReceiveFacialScore', currentSessionTotalScore);
                } else {
                    console.warn("Unity instance not found. Final score not sent for reason:", reason);
                }
            } else if (reason === "manual_close_button") { // User clicked the 'X' button
                if (window.unityGameInstance) {
                    console.log(`User manually closed modal (X button). Notifying Unity: FacialExerciseAborted. Score accumulated: ${currentSessionTotalScore}`);
                    window.unityGameInstance.SendMessage('CostManagerObject', 'FacialExerciseAborted', 0); // Send 0 or a specific abort code
                }
            } else if (window.unityGameInstance) { // For other (non-score sending) closure reasons not covered above
                 console.log(`Notifying Unity: FacialExerciseAborted due to other reason: ${reason}.`);
                 window.unityGameInstance.SendMessage('CostManagerObject', 'FacialExerciseAborted', 0);
            }


            const modal = document.getElementById('facial-recognition-modal');
            if (modal) modal.style.display = 'none';

            if (currentActiveFacialMode === 'emotion_expression') {
                if (emotionVideo && emotionVideo.srcObject) {
                    emotionVideo.srcObject.getTracks().forEach(track => track.stop());
                    emotionVideo.srcObject = null;
                }
                if (emotionModeUI) emotionModeUI.style.display = 'none';
                if (emotionGuideCanvas) emotionGuideCanvas.style.display = 'none';
            } else if (currentActiveFacialMode === 'follow_expression') {
                if (camera_Follow) camera_Follow.stop();
                if (followVideo && followVideo.srcObject) {
                    followVideo.srcObject.getTracks().forEach(track => track.stop());
                    followVideo.srcObject = null;
                }
                if (followModeUI) followModeUI.style.display = 'none';
                if (followGuideCanvas) followGuideCanvas.style.display = 'none';
            }
            
            currentActiveFacialMode = null;
            // currentSessionTotalScore is reset when ShowFacialRecognitionUI_JS is called next.
        }

        window.addEventListener('DOMContentLoaded', () => {
            console.log("DOM fully loaded. Facial recognition modal is ready.");
        });
    </script>
</body>
</html>